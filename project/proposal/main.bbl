\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Johns(2024)]{news2024}
Tim Johns.
\newblock Waymo cars honk at each other throughout the night, disturbing sf neighbors, 2024.
\newblock URL \url{https://abc7ne.ws/3Ai47Ci}.

\bibitem[Leurent(2018)]{highway-env}
Edouard Leurent.
\newblock An environment for autonomous driving decision-making.
\newblock \url{https://github.com/eleurent/highway-env}, 2018.

\bibitem[Towers et~al.(2024)Towers, Kwiatkowski, Terry, Balis, De~Cola, Deleu, Goul{\~a}o, Kallinteris, Krimmel, KG, et~al.]{towers2024gymnasium}
Mark Towers, Ariel Kwiatkowski, Jordan Terry, John~U Balis, Gianluca De~Cola, Tristan Deleu, Manuel Goul{\~a}o, Andreas Kallinteris, Markus Krimmel, Arjun KG, et~al.
\newblock Gymnasium: A standard interface for reinforcement learning environments.
\newblock \emph{arXiv preprint arXiv:2407.17032}, 2024.

\bibitem[Kapoor et~al.(2020)Kapoor, Balakrishnan, and Deshmukh]{kapoor2020model}
Parv Kapoor, Anand Balakrishnan, and Jyotirmoy~V Deshmukh.
\newblock Model-based reinforcement learning from signal temporal logic specifications.
\newblock \emph{arXiv preprint arXiv:2011.04950}, 2020.

\bibitem[Moreira(2021)]{moreira2021deep}
Dinis Moreira.
\newblock Deep reinforcement learning for automated parking.
\newblock Master's thesis, Universidade do Porto (Portugal), 2021.

\bibitem[Lazzaroni et~al.(2023)Lazzaroni, Pighetti, Bellotti, Capello, Cossu, and Berta]{lazzaroni2023automated}
Luca Lazzaroni, Alessandro Pighetti, Francesco Bellotti, Alessio Capello, Marianna Cossu, and Riccardo Berta.
\newblock Automated parking in carla: A deep reinforcement learning-based approach.
\newblock In \emph{International Conference on Applications in Electronics Pervading Industry, Environment and Society}, pages 352--357. Springer, 2023.

\bibitem[Raffin et~al.(2021)Raffin, Hill, Gleave, Kanervisto, Ernestus, and Dormann]{stable-baselines3}
Antonin Raffin, Ashley Hill, Adam Gleave, Anssi Kanervisto, Maximilian Ernestus, and Noah Dormann.
\newblock Stable-baselines3: Reliable reinforcement learning implementations.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0 (268):\penalty0 1--8, 2021.
\newblock URL \url{http://jmlr.org/papers/v22/20-1364.html}.

\bibitem[Arzt(2019)]{youtube2019}
Samuel Arzt.
\newblock Ai learns to park - deep reinforcement learning, 2019.
\newblock URL \url{https://www.youtube.com/watch?v=VMp6pq6_QjI}.

\bibitem[Euliano(2022)]{youtube2022}
Matthew Euliano.
\newblock Parallel parking using reinforcement learning - unity3d and ml-agents, 2022.
\newblock URL \url{https://www.youtube.com/watch?v=QDVwSAgY6cA}.

\bibitem[Elallid et~al.(2022)Elallid, Benamar, Hafid, Rachidi, and Mrani]{elallid2022comprehensive}
Badr~Ben Elallid, Nabil Benamar, Abdelhakim~Senhaji Hafid, Tajjeeddine Rachidi, and Nabil Mrani.
\newblock A comprehensive survey on the application of deep and reinforcement learning approaches in autonomous driving.
\newblock \emph{Journal of King Saud University-Computer and Information Sciences}, 34\penalty0 (9):\penalty0 7366--7390, 2022.

\bibitem[Yurtsever et~al.(2020)Yurtsever, Lambert, Carballo, and Takeda]{yurtsever2020survey}
Ekim Yurtsever, Jacob Lambert, Alexander Carballo, and Kazuya Takeda.
\newblock A survey of autonomous driving: Common practices and emerging technologies.
\newblock \emph{IEEE access}, 8:\penalty0 58443--58469, 2020.

\end{thebibliography}
